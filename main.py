import os
import sqlite3
import warnings
warnings.filterwarnings("ignore")

import mlflow
import mlflow.sklearn

# Importer toutes les fonctions depuis model_pipeline.py
from model_pipeline import (
    evaluate_model, load_model, predict, prepare_data,
    save_model, train_model
)

DB_PATH = os.getenv("DB_PATH", "mlflow.db")  # mlflow.db pour local, variable pour CI

def init_db(path):
    """Crée la DB et les tables si elles n'existent pas."""
    conn = sqlite3.connect(path)
    cursor = conn.cursor()

    # Exemple de table pour MLflow (ajuster si besoin)
    cursor.execute("""
        CREATE TABLE IF NOT EXISTS experiments (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            name TEXT NOT NULL,
            created_at TEXT
        )
    """)

    conn.commit()
    conn.close()

# Initialisation de la DB avant tout
init_db(DB_PATH)

def main():
    
    mlflow.set_tracking_uri("sqlite:///mlflow.db")
   # Définir l'expérience MLflowss
    mlflow.set_experiment("Loan_Prediction_RandomForest")
    #mlflow.set_default_artifact_uri("file:./artifacts")
    #mkdir artifacts

    # Démarrer un run MLflow
    with mlflow.start_run():

        # Chemins des fichiers de données
        train_path = "data/train.csv"
        test_path = "data/test.csv"

        print("=== Pipeline de Prédiction de Prêts - Modèle Random Forest ===\n")

        # Étape 1: Préparation des données
        print("1. Préparation des données...")
        data = prepare_data(train_path, test_path)
        print(f"Shape X_train: {data['X_train'].shape}")
        print(f"Shape X_test: {data['X_test'].shape}")
        print(f"Shape X_final_test: {data['X_final_test'].shape}")
        print(f"Features utilisées: {list(data['X_train'].columns)}\n")

        # Étape 2: Entraînement du modèle
        print("2. Entraînement du modèle Random Forest...")
        model = train_model(data["X_train"], data["y_train"])
        print()

        # Étape 3: Évaluation du modèle
        print("3. Évaluation du modèle...")
        results = evaluate_model(model, data["X_test"], data["y_test"])
        print()

        # Étape 4: Prédictions sur les données de test finales
        print("4. Prédictions sur les données de test...")
        final_predictions = predict(model, data["X_final_test"])
        print(f"Nombre de prédictions: {len(final_predictions)}")
        print(f"Prêts approuvés: {sum(final_predictions == 1)}")
        print(f"Prêts refusés: {sum(final_predictions == 0)}\n")

        # Étape 5: Sauvegarde du modèle
        print("5. Sauvegarde du modèle...")
        save_model(model, "random_forest_loan_model.pkl")
        mlflow.sklearn.log_model(model, artifact_path="random_forest_model")

        print()

        # Étape 6: Chargement du modèle et vérification
        print("6. Test de chargement du modèle...")
        loaded_model = load_model("random_forest_loan_model.pkl")
        test_predictions = predict(loaded_model, data["X_test"].head())
        print(f"Prédictions de test avec modèle chargé: {test_predictions}\n")

        print("=== Pipeline terminé avec succès ===")


if __name__ == "__main__":
    main()
